{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "bIbBS7nMzuD0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,classification_report,log_loss\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "id": "ZAMI_l5C2iH8"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:\\Users\\Lohesh\\Downloads\\Notes\\Machine Learning\\codes\\Bank_Personal_Loan_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "bF_HPBv42saX",
    "outputId": "bcdff408-f16d-4a64-e853-0f61079a4509"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0   1   25           1      49     91107       4    1.6          1         0   \n",
       "1   2   45          19      34     90089       3    1.5          1         0   \n",
       "2   3   39          15      11     94720       1    1.0          1         0   \n",
       "3   4   35           9     100     94112       1    2.7          2         0   \n",
       "4   5   35           8      45     91330       4    1.0          2         0   \n",
       "\n",
       "   Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0              0                   1           0       0           0  \n",
       "1              0                   1           0       0           0  \n",
       "2              0                   0           0       0           0  \n",
       "3              0                   0           0       0           0  \n",
       "4              0                   0           0       0           1  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxiWLfPA3dwT",
    "outputId": "6a3432c8-4ef9-46c6-ad68-c8fcf959d84b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "data.drop(['ID','ZIP Code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['Income']<=160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Personal Loan',axis=1).values\n",
    "Y = data['Personal Loan'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MSdljWla2_I-",
    "outputId": "865044dd-1b11-46d1-e23b-67cfb1d6dc46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3498, 11), (1167, 11), (3498,), (1167,))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtr,xtst,ytr,ytst = tts(X,Y,test_size=0.25,stratify=Y,random_state=42)\n",
    "xtr.shape,xtst.shape,ytr.shape,ytst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "xtr = sc.fit_transform(xtr)\n",
    "xtst = sc.transform(xtst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic_nn:\n",
    "    def __init__(self,ip_size):\n",
    "        self.weightstruct = []\n",
    "        self.ip_size = ip_size \n",
    "        self.act = []\n",
    "    \n",
    "    def loss_fn(pred,op):\n",
    "        return sum(abs(pred.flatten()-op.flatten()))\n",
    "    \n",
    "    def weights(self):\n",
    "        new = []\n",
    "        for i in self.weightstruct:\n",
    "            new.append(np.random.random(i)*3-0.15)\n",
    "        return new\n",
    "        \n",
    "    def layer_add(self,layer_size,activation):\n",
    "        self.act.append(activation)\n",
    "        if self.weightstruct == []:\n",
    "            self.weightstruct.append((self.ip_size+1,layer_size))\n",
    "        else:\n",
    "            prev = self.weightstruct[-1][-1]\n",
    "            self.weightstruct.append((prev+1,layer_size))\n",
    "            \n",
    "    def sigmoid(x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    \n",
    "    def ReLU(x):\n",
    "        return (x>0)*x\n",
    "    \n",
    "    def for_pro(self,ip,weights):\n",
    "        layer = ip\n",
    "        for i,j in zip(weights,self.act):\n",
    "            layer = np.append(np.ones((len(layer),1)),layer,axis=1)\n",
    "            if j=='sigmoid':\n",
    "                layer = Basic_nn.sigmoid(layer @ i)\n",
    "            else:\n",
    "                layer = Basic_nn.ReLU(layer @ i)\n",
    "        return layer\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999976],\n",
       "       [0.99999976],\n",
       "       [0.99999976],\n",
       "       ...,\n",
       "       [0.99999976],\n",
       "       [0.99999489],\n",
       "       [0.99999976]])"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial = Basic_nn(11) \n",
    "initial.layer_add(16,'ReLU') \n",
    "initial.layer_add(8,'sigmoid')\n",
    "initial.layer_add(1,'sigmoid')\n",
    "initial.weightstruct\n",
    "initial.for_pro(xtr,initial.weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genetic Algorithm adjusting Neural Network Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gene_alg:\n",
    "    def __init__(self,initial,pop_size):\n",
    "        self.initial = initial\n",
    "        self.pop_size = pop_size\n",
    "        self.population = [initial.weights() for i in range(pop_size)]\n",
    "        self.gen = 0\n",
    "        \n",
    "    def off_spr(p1,p2):\n",
    "        c1 = []\n",
    "        c2 = []\n",
    "        for i in range(len(p1)):\n",
    "            a = p1[i]\n",
    "            b = p2[i]\n",
    "            \n",
    "            ind = np.random.randint(0,2,a.shape)\n",
    "            cd1 = a*ind + b*(1^ind)\n",
    "            cd2 = a*(1^ind) + b*ind\n",
    "            \n",
    "            cd1 += (np.random.choice([0,1],cd1.shape,p=[0.7,0.3]) * np.random.random(cd1.shape)*2-0.3)\n",
    "            cd1 += (np.random.choice([0,1],cd1.shape,p=[0.7,0.3]) * np.random.random(cd2.shape)*2-0.3)\n",
    "            \n",
    "            c1.append(cd1)\n",
    "            c2.append(cd2)\n",
    "        return c1,c2\n",
    "        \n",
    "    def create(self,xtr,ytr):\n",
    "        nextgen = self.population.copy()\n",
    "        for i in range(self.pop_size-1):\n",
    "            for j in range(i,self.pop_size):\n",
    "                p1 = self.population[i]\n",
    "                p2 = self.population[j]\n",
    "                c1,c2 = gene_alg.off_spr(p1,p2)\n",
    "                nextgen.append(c1)\n",
    "                nextgen.append(c2)\n",
    "                \n",
    "        sortedgen = sorted(nextgen,key = lambda w : Basic_nn.loss_fn(initial.for_pro(xtr,w),ytr))\n",
    "        self.population = sortedgen[:self.pop_size]\n",
    "        \n",
    "        self.gen += 1\n",
    "        print(\"loss_value: %f & gene_number: %d\"%(Basic_nn.loss_fn(initial.for_pro(xtr,self.population[0]),ytr),self.gen))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = gene_alg(initial,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value: 3230.875896 & gene_number: 1\n",
      "loss_value: 581.308258 & gene_number: 2\n",
      "loss_value: 327.204270 & gene_number: 3\n",
      "loss_value: 232.506115 & gene_number: 4\n",
      "loss_value: 228.807724 & gene_number: 5\n",
      "loss_value: 228.020088 & gene_number: 6\n",
      "loss_value: 228.000339 & gene_number: 7\n",
      "loss_value: 228.000001 & gene_number: 8\n",
      "loss_value: 228.000001 & gene_number: 9\n",
      "loss_value: 228.000000 & gene_number: 10\n",
      "loss_value: 228.000000 & gene_number: 11\n",
      "loss_value: 228.000000 & gene_number: 12\n",
      "loss_value: 228.000000 & gene_number: 13\n",
      "loss_value: 228.000000 & gene_number: 14\n",
      "loss_value: 228.000000 & gene_number: 15\n",
      "loss_value: 228.000000 & gene_number: 16\n",
      "loss_value: 228.000000 & gene_number: 17\n",
      "loss_value: 228.000000 & gene_number: 18\n",
      "loss_value: 228.000000 & gene_number: 19\n",
      "loss_value: 228.000000 & gene_number: 20\n",
      "loss_value: 228.000000 & gene_number: 21\n",
      "loss_value: 228.000000 & gene_number: 22\n",
      "loss_value: 227.999999 & gene_number: 23\n",
      "loss_value: 227.999947 & gene_number: 24\n",
      "loss_value: 227.999339 & gene_number: 25\n",
      "loss_value: 227.994345 & gene_number: 26\n",
      "loss_value: 227.953963 & gene_number: 27\n",
      "loss_value: 226.529760 & gene_number: 28\n",
      "loss_value: 220.576128 & gene_number: 29\n",
      "loss_value: 215.789772 & gene_number: 30\n",
      "loss_value: 209.782881 & gene_number: 31\n",
      "loss_value: 204.234024 & gene_number: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lohesh\\AppData\\Local\\Temp\\ipykernel_23892\\3555486196.py:25: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value: 203.505802 & gene_number: 33\n",
      "loss_value: 203.472181 & gene_number: 34\n",
      "loss_value: 198.051983 & gene_number: 35\n",
      "loss_value: 193.225301 & gene_number: 36\n",
      "loss_value: 193.225301 & gene_number: 37\n",
      "loss_value: 193.225301 & gene_number: 38\n",
      "loss_value: 188.108716 & gene_number: 39\n",
      "loss_value: 188.108716 & gene_number: 40\n",
      "loss_value: 186.908667 & gene_number: 41\n",
      "loss_value: 186.908667 & gene_number: 42\n",
      "loss_value: 185.054699 & gene_number: 43\n",
      "loss_value: 185.040683 & gene_number: 44\n",
      "loss_value: 183.847078 & gene_number: 45\n",
      "loss_value: 183.847078 & gene_number: 46\n",
      "loss_value: 183.703366 & gene_number: 47\n",
      "loss_value: 183.642418 & gene_number: 48\n",
      "loss_value: 183.396096 & gene_number: 49\n",
      "loss_value: 183.165116 & gene_number: 50\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    gen.create(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98      1137\n",
      "           1       0.34      0.87      0.49        30\n",
      "\n",
      "    accuracy                           0.95      1167\n",
      "   macro avg       0.67      0.91      0.73      1167\n",
      "weighted avg       0.98      0.95      0.96      1167\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1091,   67],\n",
       "       [   0,    9]], dtype=int64)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = (initial.for_pro(xtst,gen.population[0])>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjustment of weights using Cultural Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cul_alg(gene_alg):\n",
    "    def __init__(self,initial,pop_size):\n",
    "        self.initial = initial\n",
    "        self.pop_size = pop_size\n",
    "        self.population = [base.weights() for i in range(pop_size)]\n",
    "        self.gen = 0\n",
    "        self.pb = copy.deepcopy(self.population)\n",
    "        self.gb = self.population[0]\n",
    "        \n",
    "        self.a = 0.9\n",
    "        self.b = 0.05\n",
    "        self.c = 0.05\n",
    "        self.decay_rate = 0.01\n",
    "        \n",
    "    def create(self,xtr,ytr):\n",
    "        nextgen = self.population.copy()\n",
    "        for i in range(self.pop_size-1):\n",
    "            for j in range(i,self.pop_size):\n",
    "                p1 = self.population[i]\n",
    "                p2 = self.population[j]\n",
    "                c1,c2 = gene_alg.off_spr(p1,p2)\n",
    "                nextgen.append(c1)\n",
    "                nextgen.append(c2)\n",
    "                \n",
    "        sortedgen = sorted(nextgen,key = lambda w : Basic_nn.loss_fn(initial.for_pro(xtr,w),ytr))\n",
    "        self.population = sortedgen[:self.pop_size//2]\n",
    "        \n",
    "        cfit = max(self.population,key = lambda w : self.c_score(w,xtr,ytr))\n",
    "        self.population += self.c_influence(self.population,cfit)\n",
    "        \n",
    "        self.gen += 1\n",
    "        print(\" loss: %f & generation: %d \"%(nn_base.loss(base.forward(xtr,self.population[0]),ytr),self.gen))\n",
    "        \n",
    "    def c_score(self,w,xtr,ytr):\n",
    "        pred = base.for_pro(xtr,w)\n",
    "        a = sum(ytr==1) #True count\n",
    "        b = sum(pred[np.where(ytr==1)]>0.5) #True positive count\n",
    "        return b/a\n",
    "    \n",
    "    def c_influence(self,pop,best):\n",
    "        pop1 = copy.deepcopy(pop)\n",
    "        for w in pop1:\n",
    "            for j in range(len(w)):\n",
    "                w[j] += np.random.choice([0,1],w[j].shape,p=[0.8,0.2]) * best[j]\n",
    "        return pop1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = cul_alg(base,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (38478,) (3498,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [268]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m40\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mnew\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [266]\u001b[0m, in \u001b[0;36mcul_alg.create\u001b[1;34m(self, xtr, ytr)\u001b[0m\n\u001b[0;32m     22\u001b[0m         nextgen\u001b[38;5;241m.\u001b[39mappend(c1)\n\u001b[0;32m     23\u001b[0m         nextgen\u001b[38;5;241m.\u001b[39mappend(c2)\n\u001b[1;32m---> 25\u001b[0m sortedgen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnextgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mBasic_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_pro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m=\u001b[39m sortedgen[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     28\u001b[0m cfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation,key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m w : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_score(w,xtr,ytr))\n",
      "Input \u001b[1;32mIn [266]\u001b[0m, in \u001b[0;36mcul_alg.create.<locals>.<lambda>\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m     22\u001b[0m         nextgen\u001b[38;5;241m.\u001b[39mappend(c1)\n\u001b[0;32m     23\u001b[0m         nextgen\u001b[38;5;241m.\u001b[39mappend(c2)\n\u001b[1;32m---> 25\u001b[0m sortedgen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(nextgen,key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m w : \u001b[43mBasic_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_pro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation \u001b[38;5;241m=\u001b[39m sortedgen[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     28\u001b[0m cfit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation,key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m w : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_score(w,xtr,ytr))\n",
      "Input \u001b[1;32mIn [250]\u001b[0m, in \u001b[0;36mBasic_nn.loss_fn\u001b[1;34m(pred, op)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(pred,op):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mabs\u001b[39m(\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (38478,) (3498,) "
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    new.create(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = (initial.for_pro(xtst,new.population[0])>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle swarm Optimiztaion on Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class swarm:\n",
    "    def __init__(self,initial,pop_size):\n",
    "        self.initial = initial\n",
    "        self.pop_size = pop_size\n",
    "        self.population = [base.weights() for i in range(pop_size)]\n",
    "        self.gen = 0\n",
    "        self.pb = copy.deepcopy(self.population)\n",
    "        self.gb = self.population[0]\n",
    "        \n",
    "        self.a = 0.9\n",
    "        self.b = 0.05\n",
    "        self.c = 0.05\n",
    "        self.decay_rate = 0.01\n",
    "        \n",
    "    def param_upd(self):\n",
    "        self.a-=(self.a*self.decay_rate)\n",
    "        \n",
    "    def best_upd(self,xtr,ytr):\n",
    "        loss = lambda w : Basic_nn.loss_fn(initial.for_pro(xtr,w),ytr)\n",
    "        \n",
    "        for ind in range(self.pop_size):\n",
    "            w = self.population[ind]\n",
    "            \n",
    "            if loss(w) < loss(self.pb[ind]):\n",
    "                self.pb[ind] = copy.deepcopy(w)\n",
    "                \n",
    "            if loss(self.pb[ind]) < loss(self.gb):\n",
    "                self.gb = copy.deepcopy(self.pb[ind])\n",
    "                \n",
    "        print(\" loss_value: %f & gene_number: %d\"%(loss(self.gb),self.gen))\n",
    "        \n",
    "    def upd(self):\n",
    "        for ind in range(self.pop_size):\n",
    "            w = self.population[ind]\n",
    "            pb = self.pb[ind]\n",
    "            for i in range(len(w)):\n",
    "                r1, r2 = np.random.rand(2)\n",
    "                w[i] = self.a*w[i] + self.b*r1*(pb[i]-w[i]) + self.c*r2*(self.gb[i]-w[i])\n",
    "                \n",
    "    def create(self,xtr,ytr):\n",
    "        self.upd()\n",
    "        self.best_upd(xtr,ytr)\n",
    "        self.gen += 1\n",
    "        if self.gen%10==0:\n",
    "            self.param_upd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12, 16), (17, 8), (9, 1)]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swarm_base = Basic_nn(11)\n",
    "swarm_base.layer_add(16,'ReLU')\n",
    "swarm_base.layer_add(8,'sigmoid')\n",
    "swarm_base.layer_add(1,'sigmoid')\n",
    "swarm_base.weightstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle = swarm(initial,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (38478,) (3498,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [278]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mparticle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [269]\u001b[0m, in \u001b[0;36mswarm.create\u001b[1;34m(self, xtr, ytr)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\u001b[38;5;28mself\u001b[39m,xtr,ytr):\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupd()\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_upd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "Input \u001b[1;32mIn [269]\u001b[0m, in \u001b[0;36mswarm.best_upd\u001b[1;34m(self, xtr, ytr)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size):\n\u001b[0;32m     22\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[ind]\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m<\u001b[39m loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpb[ind]):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpb[ind] \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(w)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpb[ind]) \u001b[38;5;241m<\u001b[39m loss(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgb):\n",
      "Input \u001b[1;32mIn [269]\u001b[0m, in \u001b[0;36mswarm.best_upd.<locals>.<lambda>\u001b[1;34m(w)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbest_upd\u001b[39m(\u001b[38;5;28mself\u001b[39m,xtr,ytr):\n\u001b[1;32m---> 19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m w : \u001b[43mBasic_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfor_pro\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpop_size):\n\u001b[0;32m     22\u001b[0m         w \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation[ind]\n",
      "Input \u001b[1;32mIn [250]\u001b[0m, in \u001b[0;36mBasic_nn.loss_fn\u001b[1;34m(pred, op)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(pred,op):\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mabs\u001b[39m(\u001b[43mpred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (38478,) (3498,) "
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    particle.create(xtr,ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [279]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m ans \u001b[38;5;241m=\u001b[39m (initial\u001b[38;5;241m.\u001b[39mfor_pro(xtst,particle\u001b[38;5;241m.\u001b[39mgb)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytst\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:307\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(\n\u001b[0;32m    223\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    224\u001b[0m ):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 307\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "ans = (initial.for_pro(xtst,particle.gb)>0.5).astype(int)\n",
    "confusion_matrix(ans,ytst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [280]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m,\u001b[49m\u001b[43mytst\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2110\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   1998\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassification_report\u001b[39m(\n\u001b[0;32m   1999\u001b[0m     y_true,\n\u001b[0;32m   2000\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2007\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2008\u001b[0m ):\n\u001b[0;32m   2009\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[0;32m   2010\u001b[0m \n\u001b[0;32m   2011\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2107\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[0;32m   2108\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2110\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2113\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and binary targets"
     ]
    }
   ],
   "source": [
    "print(classification_report(ans,ytst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANT colony Optimization for weight adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Ant:\n",
    "    def __init__(self, num_weights):\n",
    "        self.weights = np.random.rand(num_weights)\n",
    "        self.fitness = 0.0\n",
    "\n",
    "    def evaluate_fitness(self, fitness_func):\n",
    "        self.fitness = fitness_func(self.weights)\n",
    "\n",
    "class ACO:\n",
    "    def __init__(self, pop_size, num_weights, q, alpha, beta, rho, num_iterations):\n",
    "        self.pop_size = pop_size\n",
    "        self.num_weights = num_weights\n",
    "        self.q = q\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.rho = rho\n",
    "        self.num_iterations = num_iterations\n",
    "        self.pheromone = np.ones(num_weights)\n",
    "        self.best_ant = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.population = [Ant(num_weights) for _ in range(pop_size)]\n",
    "\n",
    "    def update_pheromone(self, ant):\n",
    "        self.pheromone *= (1.0 - self.rho)\n",
    "        self.pheromone += (self.q / ant.fitness) * ant.weights\n",
    "\n",
    "    def select_weights(self):\n",
    "        weights = np.zeros(self.num_weights)\n",
    "        for i in range(self.num_weights):\n",
    "            if np.random.rand() < self.pheromone[i]:\n",
    "                weights[i] = 1\n",
    "        return weights\n",
    "\n",
    "    def update_population(self, fitness_func):\n",
    "        for ant in self.population:\n",
    "            weights = self.select_weights()\n",
    "            ant.weights = weights\n",
    "            ant.evaluate_fitness(fitness_func)\n",
    "            if ant.fitness < self.best_fitness:\n",
    "                self.best_fitness = ant.fitness\n",
    "                self.best_ant = ant\n",
    "            self.update_pheromone(ant)\n",
    "\n",
    "    def evolve(self, fitness_func):\n",
    "        for i in range(self.num_iterations):\n",
    "            self.update_population(fitness_func)\n",
    "        return self.best_ant.weights\n",
    "    \n",
    "    def fitness_func(self,weights):\n",
    "        model.set_weights(weights)\n",
    "        model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))\n",
    "        loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "        return -loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fitness_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [287]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m num_iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      9\u001b[0m aco \u001b[38;5;241m=\u001b[39m ACO(pop_size, num_weights, q, alpha, beta, rho, num_iterations)\n\u001b[1;32m---> 11\u001b[0m optimal_weights \u001b[38;5;241m=\u001b[39m aco\u001b[38;5;241m.\u001b[39mevolve(\u001b[43mfitness_func\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'fitness_func' is not defined"
     ]
    }
   ],
   "source": [
    "pop_size = 100\n",
    "num_weights = 337\n",
    "q = 0.1\n",
    "alpha = 1.0\n",
    "beta = 2.0\n",
    "rho = 0.5\n",
    "num_iterations = 100\n",
    "\n",
    "aco = ACO(pop_size, num_weights, q, alpha, beta, rho, num_iterations)\n",
    "\n",
    "optimal_weights = aco.evolve(fitness_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
